{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4t6w/MTWMpQ/9x5x7OxP1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahyakesenek/KOU/blob/master/neuralnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n15SJTNK6F7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0a5ff42e-bd38-4c85-e20d-e67e78f08f04"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import cv2\n",
        "import matplotlib.pyplot as pl\n",
        "\n",
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "img=x_train[0]\n",
        "#img = cv2.imread(x_train[0],cv2.IMREAD_GRAYSCALE)/255\n",
        "pl.imshow(img,cmap=\"gray\")\n",
        "pl.show()\n",
        "img.shape\n",
        "\n",
        "class Conv:\n",
        "  def __init__(self,num_filters,filter_size):\n",
        "    self.num_filters=num_filters\n",
        "    self.filter_size=filter_size\n",
        "    self.conv_filter=np.random.randn(num_filters,filter_size,filter_size)/(filter_size*filter_size)#(x,4,4)=> 16 ya bölünerek nırmalize edilir.\n",
        "\n",
        "  def image_region(self,image):#parça üretim amacıyla kullanılmaktadır. n-x+1 patch boyutu\n",
        "    height,width=image.shape\n",
        "    self.image = image\n",
        "    for j in range(height-self.filter_size+1):\n",
        "      for k in range(width-self.filter_size+1):\n",
        "        image_patch=image[j:(j+self.filter_size),k:(k+self.filter_size)]\n",
        "        yield image_patch,j,k\n",
        "  def forward_prop(self,image):\n",
        "    height,width=image.shape\n",
        "    conv_out=np.zeros((height-self.filter_size+1,width-self.filter_size+1,self.num_filters))\n",
        "    for image_patch,i,j in self.image_region(image):\n",
        "      conv_out[i,j] = np.sum(image_patch*self.conv_filter,axis=(1,2))\n",
        "    return conv_out\n",
        "  def back_prop(self,dl_dout,learning_rate):#dl_dout -> max-pool değeriyle gelecek\n",
        "    dl=np.zeros(self.conv_filter.shape)\n",
        "    for image_patch,i,j in self.image_region(self.image):\n",
        "      for k in range(self.num_filters):\n",
        "        dl[k] +=image_patch*dl_dout[i,j,k]\n",
        "    self.conv_filter -=learning_rate*dl\n",
        "    return dl\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKlc8ii6YAAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "412f6465-3c3e-4c85-863f-39ccc998b1d4"
      },
      "source": [
        "conv = Conv(18,7)\n",
        "out = conv.forward_prop(img)\n",
        "print(img.shape)\n",
        "print(out.shape)\n",
        "pl.imshow(out[:,:,8],cmap=\"gray\") # 3 değeri 0-17 a kadar değer alabilir\n",
        "pl.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(22, 22, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEQxfLqeaVxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaxPool:\n",
        "  def __init__(self,filter_size):\n",
        "    self.filter_size=filter_size\n",
        "  def image_region(self,image):#parça üretim amacıyla kullanılmaktadır. n-x+1 patch boyutu\n",
        "    height,width=image.shape[0]//self.filter_size,image.shape[1]//self.filter_size\n",
        "    self.image=image\n",
        "    for i in range(height-self.filter_size+1):\n",
        "      for j in range(width-self.filter_size+1):\n",
        "        image_patch=image[(i*self.filter_size):(i*self.filter_size+self.filter_size),(j*self.filter_size):(j*self.filter_size+self.filter_size)]\n",
        "        yield image_patch,i,j\n",
        "    \n",
        "  def forward_prop(self,image):\n",
        "    height,width,num_filters=image.shape\n",
        "    self.num_filters=num_filters\n",
        "    conv_out=np.zeros((height//self.filter_size,width//self.filter_size,num_filters))\n",
        "    for image_patch,i,j in self.image_region(image):\n",
        "      conv_out[i,j] = np.amax(image_patch*self.filter_size,axis=(0,1))\n",
        "    return conv_out\n",
        "  def back_prop(self,dl_dout):#softmax kullanımına dikkat edilecek  dl_out bir softmax\n",
        "    dl=np.zeros(self.image.shape)\n",
        "    for image_patch,i,j in self.image_region(self.image):\n",
        "      for k in range(self.num_filters):\n",
        "        h,w,filter = image_patch.shape\n",
        "        max_val=np.amax(image_patch,axis=(0,1))\n",
        "        for i1 in range(h):\n",
        "          for j1 in range(w):\n",
        "            for k1 in range(filter):\n",
        "              if image_patch[i1,j1,k1] == max_val[k1]:\n",
        "                dl[i*self.filter_size+i1,j*self.filter_size+j1,k1]=dl_dout[j,j,k1]\n",
        "    \n",
        "    return dl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tbQPnwneVJC",
        "colab_type": "code",
        "outputId": "db788a38-d134-4c41-d8bb-b2024bbc3f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "maxpol = MaxPool(4)\n",
        "out = maxpol.forward_prop(out)\n",
        "print(out.shape)\n",
        "pl.imshow(out[:,:,7],cmap=\"gray\")\n",
        "pl.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 5, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAIuElEQVR4nO3dQYic9R3G8efJboJSAx5qIGRD40GEIGmEEIT0UAJCrEF7NNAegrCXChFaxPZQ8NBbKV68BBsUFEXQg4SABBpqCza6G2NrEoUgFleEpUipoVCJ+/Swc4jtzs67k/edd+eX7wcWZibvvPMj2e/+33knvOskAlDHlr4HANAuogaKIWqgGKIGiiFqoJjZLna6ZcuWzM52suvW7du3r+8RNmRxcbHvEbBJJPFaj7uLj7S2bduWHTt2tL7fLiwtLfU9wobYa/474hY0LGoOv4FiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWIaRW37iO2PbV+1/XTXQwEY38iobc9Iek7SQ5L2Sjpme2/XgwEYT5OV+qCkq0k+SfK1pFclPdrtWADG1STqXZI+u+H+0uCxb7E9b3vB9sLKykpb8wHYoNZOlCU5meRAkgNbtnD+DehLk/o+l7T7hvtzg8cAbEJNon5P0j2277a9TdJjkt7sdiwA4xr5azSSXLf9hKS3JM1IOpXkUueTARhLo9+Nk+SMpDMdzwKgBZzRAoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgmEYXSdiomZkZbd++vYtdt+748eN9jwC0ipUaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBooZmTUtk/ZXrb94SQGAnBzmqzUL0g60vEcAFoyMuokb0v6cgKzAGgB76mBYlq7mqjteUnzkjQ728lFSgE00NpKneRkkgNJDhA10B8Ov4Fimnyk9YqkdyTda3vJ9uPdjwVgXCOPk5Mcm8QgANrB4TdQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8U4Sfs7tdvfKYBvSeK1HmelBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoJiRUdvebfuc7cu2L9k+MYnBAIxn5DXKbO+UtDPJBdvbJS1K+nGSy+s8h2uUAR0b+xplSb5IcmFw+ytJVyTtanc8AG2Z3cjGtvdIul/S+TX+bF7SfCtTARhb40sE275D0h8l/SbJGyO25fAb6NhNXSLY9lZJr0t6eVTQAPrV5ESZJb0o6cskTzbaKSs10LlhK3WTqH8g6U+S/iZpZfDwr5KcWec5RA10bOyox0HUQPf4tTvALYKogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiRkZt+zbb79r+wPYl289MYjAA43GS9TewLek7Sa7Z3irpz5JOJPnLOs9Zf6cAbloSr/X4bIMnRtK1wd2tgy+iBTapRu+pbc/YvihpWdLZJOe7HQvAuBpFneSbJPslzUk6aPu+/93G9rztBdsLbQ8JoLmR76n/7wn2ryX9O8lv19mGw3OgY8PeUzc5+32X7TsHt2+X9KCkj9odD0BbRp4ok7RT0ou2Z7T6Q+C1JKe7HQvAuDZ8+N1opxx+A50b+/AbwHQhaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGimkcte0Z2+/bPt3lQABuzkZW6hOSrnQ1CIB2NIra9pykhyU93+04AG5W05X6WUlPSVoZtoHtedsLthdamQzAWEZGbfuopOUki+ttl+RkkgNJDrQ2HYANa7JSH5L0iO1PJb0q6bDtlzqdCsDYnKT5xvYPJf0iydER2zXfKYCxJPFaj/M5NVDMhlbqxjtlpQY6x0oN3CKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBooZraj/f5D0t9b3ud3B/udFtM07zTNKk3XvF3N+r1hf9DJlU+6YHthmq5UOk3zTtOs0nTN28esHH4DxRA1UMw0RX2y7wE2aJrmnaZZpemad+KzTs17agDNTNNKDaABogaKmYqobR+x/bHtq7af7nue9dg+ZXvZ9od9zzKK7d22z9m+bPuS7RN9zzSM7dtsv2v7g8Gsz/Q9UxO2Z2y/b/v0pF5z00dte0bSc5IekrRX0jHbe/udal0vSDrS9xANXZf08yR7JT0g6Web+O/2P5IOJ/m+pP2Sjth+oOeZmjgh6cokX3DTRy3poKSrST5J8rVWf/Pmoz3PNFSStyV92fccTST5IsmFwe2vtPrNt6vfqdaWVdcGd7cOvjb1WV7bc5IelvT8JF93GqLeJemzG+4vaZN+400z23sk3S/pfL+TDDc4lL0oaVnS2SSbdtaBZyU9JWllki86DVGjY7bvkPS6pCeT/KvveYZJ8k2S/ZLmJB20fV/fMw1j+6ik5SSLk37taYj6c0m7b7g/N3gMLbC9VatBv5zkjb7naSLJPyWd0+Y+d3FI0iO2P9XqW8bDtl+axAtPQ9TvSbrH9t22t0l6TNKbPc9Ugm1L+r2kK0l+1/c867F9l+07B7dvl/SgpI/6nWq4JL9MMpdkj1a/Z/+Q5CeTeO1NH3WS65KekPSWVk/kvJbkUr9TDWf7FUnvSLrX9pLtx/ueaR2HJP1Uq6vIxcHXj/oeaoidks7Z/qtWf9CfTTKxj4mmCf9NFChm06/UADaGqIFiiBoohqiBYogaKIaogWKIGijmv79R6qOd+db1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kto1bcAhhBtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Softmax:\n",
        "  def __init__(self,_input,soft):\n",
        "    self.weight=np.random.randn(_input,soft)/_input\n",
        "    self.bias = np.zeros(soft)\n",
        "  def forward(self,image):\n",
        "    self.orig_im_shape = image.shape\n",
        "    flattened = image.flatten()\n",
        "    self.modified = flattened\n",
        "    self.out=np.dot(self.modified,self.weight)+self.bias\n",
        "    exp_out = np.exp(self.out)\n",
        "    return exp_out/np.sum(exp_out,axis=0)\n",
        "  def backwad(self,dl_dout,learning_rate):\n",
        "    for i,grad in enumerate(dl_dout):\n",
        "      if grad == 0:\n",
        "        continue\n",
        "      transformation = np.exp(self.out)\n",
        "      s_total = np.sum(transformation)\n",
        "      dy_dz = -transformation[i]*transformation/(s_total**2)#z ye göre türev\n",
        "      dy_dz[i] = transformation[i]*(s_total-transformation[i])/(s_total**2)\n",
        "\n",
        "      dz_dw = self.modified\n",
        "      dz_db = 1\n",
        "      dz_input = self.weight\n",
        "\n",
        "      dL_dz=grad*dy_dz\n",
        "      dL_dw = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
        "      dL_db = dL_dz*dz_db\n",
        "      dL_input = dz_input@dL_dz\n",
        "\n",
        "      self.weight -= learning_rate*dL_dw\n",
        "      self.bias -=learning_rate*dL_db\n",
        "      return dL_input.reshape(self.orig_im_shape)\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyRqA8Ljicr",
        "colab_type": "code",
        "outputId": "88ea702d-c79c-4358-9f98-7111b0d5e7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "s=Softmax(5*5*18,10)\n",
        "out = s.forward(out)\n",
        "print(out)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02239518 0.08009746 0.29065291 0.02150349 0.00658305 0.29028761\n",
            " 0.14689862 0.01673528 0.06277599 0.06207042]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVaYrZKVkfrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mConv = Conv(8,3) # (28,28,1)=>(26,26,8)\n",
        "mPool = MaxPool(4) # (26,26,8) => (13,13,8)\n",
        "mSoftmax = Softmax(6*6*8,10) # (13*13*10) => 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLYMKvnOlPFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(img,label):\n",
        "  out=mConv.forward_prop(img/255)\n",
        "  out=mPool.forward_prop(out)\n",
        "  out=mSoftmax.forward(out)\n",
        "\n",
        "  cross_ent = -np.log(out[label])\n",
        "  accuracy = 1 if np.argmax(out) == label else 0\n",
        "  return out,cross_ent,accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-jt4t6IlxMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(img,label,learning_rate=0.005):\n",
        "  out,loss,acc = forward(img,label)\n",
        "  grad = np.zeros(10)\n",
        "  grad[label] = -1/out[label]\n",
        "  grad_back = mSoftmax.backwad(grad,learning_rate)\n",
        "  grad_back = mPool.back_prop(grad_back)\n",
        "  grad_back = mConv.back_prop(grad_back,learning_rate)\n",
        "  return loss,acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nuO6z6um4aF",
        "colab_type": "code",
        "outputId": "3d61424f-2f72-447f-8de6-1c7b9f7b05d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoc in range(10):\n",
        "  print(\"Epoch => {}\".format(epoc+1))\n",
        "  loss = 0\n",
        "  num_correct = 0\n",
        "  for i,(im,label) in enumerate(zip(x_train,y_train)):\n",
        "    if i % 100 == 0 and i>0:\n",
        "      print(\"{} steps out of 100 steps : average {}  and accuracy {}\".format(i+1,loss/100,num_correct))\n",
        "      loss=0\n",
        "      num_correct=0\n",
        "    l1,acc=train(im,label)\n",
        "    loss+=l1\n",
        "    num_correct+=acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch => 1\n",
            "101 steps out of 100 steps : average 2.2654090572298533  and accuracy 14\n",
            "201 steps out of 100 steps : average 2.2074985548621937  and accuracy 18\n",
            "301 steps out of 100 steps : average 2.1711532859322182  and accuracy 28\n",
            "401 steps out of 100 steps : average 2.1127184499663967  and accuracy 32\n",
            "501 steps out of 100 steps : average 2.056891865135076  and accuracy 35\n",
            "601 steps out of 100 steps : average 2.0779536987661915  and accuracy 34\n",
            "701 steps out of 100 steps : average 2.045647493108663  and accuracy 35\n",
            "801 steps out of 100 steps : average 2.028149610301059  and accuracy 32\n",
            "901 steps out of 100 steps : average 1.9983590919506329  and accuracy 35\n",
            "1001 steps out of 100 steps : average 1.9534673693528768  and accuracy 37\n",
            "1101 steps out of 100 steps : average 1.9690819663798131  and accuracy 41\n",
            "1201 steps out of 100 steps : average 1.9382714768673417  and accuracy 37\n",
            "1301 steps out of 100 steps : average 1.8602901822709694  and accuracy 51\n",
            "1401 steps out of 100 steps : average 1.8769956320716699  and accuracy 49\n",
            "1501 steps out of 100 steps : average 1.856133564306806  and accuracy 41\n",
            "1601 steps out of 100 steps : average 1.8618438279361353  and accuracy 35\n",
            "1701 steps out of 100 steps : average 1.6689149490448723  and accuracy 56\n",
            "1801 steps out of 100 steps : average 1.6735216631097216  and accuracy 52\n",
            "1901 steps out of 100 steps : average 1.7349641236997961  and accuracy 57\n",
            "2001 steps out of 100 steps : average 1.66478876951144  and accuracy 54\n",
            "2101 steps out of 100 steps : average 1.6774190190514013  and accuracy 55\n",
            "2201 steps out of 100 steps : average 1.6831223651965326  and accuracy 49\n",
            "2301 steps out of 100 steps : average 1.4235223330367186  and accuracy 54\n",
            "2401 steps out of 100 steps : average 1.6827200738658836  and accuracy 52\n",
            "2501 steps out of 100 steps : average 1.7128617099294743  and accuracy 37\n",
            "2601 steps out of 100 steps : average 1.5533283679790493  and accuracy 50\n",
            "2701 steps out of 100 steps : average 1.5794358406408804  and accuracy 47\n",
            "2801 steps out of 100 steps : average 1.4918987631108311  and accuracy 52\n",
            "2901 steps out of 100 steps : average 1.4799337191982562  and accuracy 60\n",
            "3001 steps out of 100 steps : average 1.5167639775095563  and accuracy 55\n",
            "3101 steps out of 100 steps : average 1.584268553641212  and accuracy 46\n",
            "3201 steps out of 100 steps : average 1.5124338371629478  and accuracy 53\n",
            "3301 steps out of 100 steps : average 1.4238522251512518  and accuracy 56\n",
            "3401 steps out of 100 steps : average 1.412036134504811  and accuracy 50\n",
            "3501 steps out of 100 steps : average 1.4841123323939138  and accuracy 55\n",
            "3601 steps out of 100 steps : average 1.5049674364064691  and accuracy 55\n",
            "3701 steps out of 100 steps : average 1.3221539469860428  and accuracy 63\n",
            "3801 steps out of 100 steps : average 1.470068690588257  and accuracy 61\n",
            "3901 steps out of 100 steps : average 1.3470039617822473  and accuracy 61\n",
            "4001 steps out of 100 steps : average 1.54289675411622  and accuracy 55\n",
            "4101 steps out of 100 steps : average 1.472347245955121  and accuracy 56\n",
            "4201 steps out of 100 steps : average 1.515075497604334  and accuracy 51\n",
            "4301 steps out of 100 steps : average 1.396909763912518  and accuracy 56\n",
            "4401 steps out of 100 steps : average 1.4875832104428064  and accuracy 48\n",
            "4501 steps out of 100 steps : average 1.3556917532870252  and accuracy 53\n",
            "4601 steps out of 100 steps : average 1.1926731603539074  and accuracy 68\n",
            "4701 steps out of 100 steps : average 1.2687978903164423  and accuracy 59\n",
            "4801 steps out of 100 steps : average 1.2894755606261699  and accuracy 57\n",
            "4901 steps out of 100 steps : average 1.2246023351698914  and accuracy 63\n",
            "5001 steps out of 100 steps : average 1.4319367395419942  and accuracy 56\n",
            "5101 steps out of 100 steps : average 1.4159513192683792  and accuracy 49\n",
            "5201 steps out of 100 steps : average 1.4130435719372927  and accuracy 54\n",
            "5301 steps out of 100 steps : average 1.4865275186574523  and accuracy 53\n",
            "5401 steps out of 100 steps : average 1.1887368348315248  and accuracy 57\n",
            "5501 steps out of 100 steps : average 1.107278509561186  and accuracy 66\n",
            "5601 steps out of 100 steps : average 1.2921498450818287  and accuracy 61\n",
            "5701 steps out of 100 steps : average 1.3272221162263194  and accuracy 58\n",
            "5801 steps out of 100 steps : average 1.4753402337914159  and accuracy 57\n",
            "5901 steps out of 100 steps : average 1.635410600650179  and accuracy 46\n",
            "6001 steps out of 100 steps : average 1.2947052646578947  and accuracy 61\n",
            "6101 steps out of 100 steps : average 1.0778777663586014  and accuracy 66\n",
            "6201 steps out of 100 steps : average 1.0428289763395804  and accuracy 73\n",
            "6301 steps out of 100 steps : average 1.2749349327183475  and accuracy 62\n",
            "6401 steps out of 100 steps : average 1.2751751652788474  and accuracy 57\n",
            "6501 steps out of 100 steps : average 1.2005163051077345  and accuracy 62\n",
            "6601 steps out of 100 steps : average 0.868756725619531  and accuracy 78\n",
            "6701 steps out of 100 steps : average 1.2141265322984527  and accuracy 64\n",
            "6801 steps out of 100 steps : average 1.26702685791329  and accuracy 55\n",
            "6901 steps out of 100 steps : average 1.5124753142331864  and accuracy 50\n",
            "7001 steps out of 100 steps : average 1.2837516095729986  and accuracy 62\n",
            "7101 steps out of 100 steps : average 1.230489342909037  and accuracy 60\n",
            "7201 steps out of 100 steps : average 1.4085722550945516  and accuracy 54\n",
            "7301 steps out of 100 steps : average 1.3514287541899899  and accuracy 61\n",
            "7401 steps out of 100 steps : average 1.397250465978109  and accuracy 52\n",
            "7501 steps out of 100 steps : average 1.1920958336725462  and accuracy 60\n",
            "7601 steps out of 100 steps : average 1.0209131718235585  and accuracy 63\n",
            "7701 steps out of 100 steps : average 1.1505331494261584  and accuracy 65\n",
            "7801 steps out of 100 steps : average 1.3010361449435583  and accuracy 55\n",
            "7901 steps out of 100 steps : average 1.3189971809945868  and accuracy 59\n",
            "8001 steps out of 100 steps : average 1.0744587004882677  and accuracy 61\n",
            "8101 steps out of 100 steps : average 1.0157074469940313  and accuracy 74\n",
            "8201 steps out of 100 steps : average 1.1637586254455485  and accuracy 62\n",
            "8301 steps out of 100 steps : average 1.5814887584599113  and accuracy 49\n",
            "8401 steps out of 100 steps : average 1.1413277833733533  and accuracy 60\n",
            "8501 steps out of 100 steps : average 1.2690164415475609  and accuracy 64\n",
            "8601 steps out of 100 steps : average 0.8124636784835851  and accuracy 78\n",
            "8701 steps out of 100 steps : average 1.3264763201201422  and accuracy 58\n",
            "8801 steps out of 100 steps : average 1.4860155764053158  and accuracy 50\n",
            "8901 steps out of 100 steps : average 1.3271012018514452  and accuracy 48\n",
            "9001 steps out of 100 steps : average 1.0243913671334388  and accuracy 68\n",
            "9101 steps out of 100 steps : average 0.9371721030271147  and accuracy 69\n",
            "9201 steps out of 100 steps : average 1.2253603513290923  and accuracy 59\n",
            "9301 steps out of 100 steps : average 1.1199997610019228  and accuracy 64\n",
            "9401 steps out of 100 steps : average 1.0473596568941228  and accuracy 66\n",
            "9501 steps out of 100 steps : average 1.050454044615179  and accuracy 69\n",
            "9601 steps out of 100 steps : average 1.1610490161772171  and accuracy 60\n",
            "9701 steps out of 100 steps : average 0.8859609149920235  and accuracy 65\n",
            "9801 steps out of 100 steps : average 0.9234570192098261  and accuracy 73\n",
            "9901 steps out of 100 steps : average 1.0353776577019767  and accuracy 67\n",
            "10001 steps out of 100 steps : average 1.1139914516612266  and accuracy 61\n",
            "10101 steps out of 100 steps : average 1.2261165898356117  and accuracy 55\n",
            "10201 steps out of 100 steps : average 1.2512897987427574  and accuracy 60\n",
            "10301 steps out of 100 steps : average 1.344567336188139  and accuracy 55\n",
            "10401 steps out of 100 steps : average 0.9845136870841561  and accuracy 68\n",
            "10501 steps out of 100 steps : average 0.9869027837761501  and accuracy 65\n",
            "10601 steps out of 100 steps : average 1.104232873092102  and accuracy 61\n",
            "10701 steps out of 100 steps : average 0.8761062780342221  and accuracy 71\n",
            "10801 steps out of 100 steps : average 1.099675215532395  and accuracy 64\n",
            "10901 steps out of 100 steps : average 1.0459024412602107  and accuracy 70\n",
            "11001 steps out of 100 steps : average 1.127244696775441  and accuracy 68\n",
            "11101 steps out of 100 steps : average 1.0015080559438791  and accuracy 68\n",
            "11201 steps out of 100 steps : average 1.1156551560924817  and accuracy 58\n",
            "11301 steps out of 100 steps : average 0.9279220322851519  and accuracy 73\n",
            "11401 steps out of 100 steps : average 1.1462142001826316  and accuracy 63\n",
            "11501 steps out of 100 steps : average 1.0272572719490398  and accuracy 63\n",
            "11601 steps out of 100 steps : average 1.384606284429112  and accuracy 55\n",
            "11701 steps out of 100 steps : average 1.3652921412687464  and accuracy 55\n",
            "11801 steps out of 100 steps : average 1.3524093421939134  and accuracy 58\n",
            "11901 steps out of 100 steps : average 1.2730845889575153  and accuracy 57\n",
            "12001 steps out of 100 steps : average 1.1685850245092588  and accuracy 63\n",
            "12101 steps out of 100 steps : average 1.0558669356288304  and accuracy 67\n",
            "12201 steps out of 100 steps : average 0.864190041047312  and accuracy 76\n",
            "12301 steps out of 100 steps : average 1.095281173645576  and accuracy 61\n",
            "12401 steps out of 100 steps : average 0.9904041761056875  and accuracy 64\n",
            "12501 steps out of 100 steps : average 1.098982568981088  and accuracy 59\n",
            "12601 steps out of 100 steps : average 1.223695927177381  and accuracy 53\n",
            "12701 steps out of 100 steps : average 1.1739365463645297  and accuracy 60\n",
            "12801 steps out of 100 steps : average 1.0300789182569166  and accuracy 67\n",
            "12901 steps out of 100 steps : average 0.9224081465290923  and accuracy 71\n",
            "13001 steps out of 100 steps : average 1.1491261497828116  and accuracy 58\n",
            "13101 steps out of 100 steps : average 1.3946192270956377  and accuracy 48\n",
            "13201 steps out of 100 steps : average 1.16348691442214  and accuracy 58\n",
            "13301 steps out of 100 steps : average 0.9719365755451028  and accuracy 65\n",
            "13401 steps out of 100 steps : average 1.1361010089411034  and accuracy 60\n",
            "13501 steps out of 100 steps : average 0.8450619572180181  and accuracy 76\n",
            "13601 steps out of 100 steps : average 0.8057583402421972  and accuracy 74\n",
            "13701 steps out of 100 steps : average 1.0301997808373067  and accuracy 67\n",
            "13801 steps out of 100 steps : average 1.1724918274875022  and accuracy 59\n",
            "13901 steps out of 100 steps : average 1.077510267137721  and accuracy 60\n",
            "14001 steps out of 100 steps : average 1.378147742641198  and accuracy 60\n",
            "14101 steps out of 100 steps : average 1.0235588106411926  and accuracy 61\n",
            "14201 steps out of 100 steps : average 1.1339068356364852  and accuracy 61\n",
            "14301 steps out of 100 steps : average 1.1304693791049192  and accuracy 63\n",
            "14401 steps out of 100 steps : average 1.2653051767845935  and accuracy 58\n",
            "14501 steps out of 100 steps : average 0.995708169496805  and accuracy 60\n",
            "14601 steps out of 100 steps : average 1.168639171136469  and accuracy 53\n",
            "14701 steps out of 100 steps : average 1.0148458618196166  and accuracy 66\n",
            "14801 steps out of 100 steps : average 1.118001837936359  and accuracy 66\n",
            "14901 steps out of 100 steps : average 0.9535979412996243  and accuracy 69\n",
            "15001 steps out of 100 steps : average 1.1162832407064753  and accuracy 70\n",
            "15101 steps out of 100 steps : average 1.1463329138822391  and accuracy 65\n",
            "15201 steps out of 100 steps : average 1.0755012265166628  and accuracy 61\n",
            "15301 steps out of 100 steps : average 0.9570645377003418  and accuracy 73\n",
            "15401 steps out of 100 steps : average 1.0661446634390745  and accuracy 67\n",
            "15501 steps out of 100 steps : average 1.1814375145798253  and accuracy 64\n",
            "15601 steps out of 100 steps : average 1.0446566274181277  and accuracy 61\n",
            "15701 steps out of 100 steps : average 1.0454768556684155  and accuracy 67\n",
            "15801 steps out of 100 steps : average 1.4058923889865917  and accuracy 54\n",
            "15901 steps out of 100 steps : average 1.323582667027268  and accuracy 55\n",
            "16001 steps out of 100 steps : average 1.0218268160825368  and accuracy 64\n",
            "16101 steps out of 100 steps : average 1.2053454241655028  and accuracy 56\n",
            "16201 steps out of 100 steps : average 1.1776156908768132  and accuracy 59\n",
            "16301 steps out of 100 steps : average 0.9388423581291205  and accuracy 69\n",
            "16401 steps out of 100 steps : average 0.8878723857598739  and accuracy 72\n",
            "16501 steps out of 100 steps : average 0.9415802752411758  and accuracy 78\n",
            "16601 steps out of 100 steps : average 0.8315398159807467  and accuracy 70\n",
            "16701 steps out of 100 steps : average 1.1734097592663044  and accuracy 61\n",
            "16801 steps out of 100 steps : average 1.1438231156341323  and accuracy 61\n",
            "16901 steps out of 100 steps : average 1.1058200738463175  and accuracy 59\n",
            "17001 steps out of 100 steps : average 1.0676290782674456  and accuracy 65\n",
            "17101 steps out of 100 steps : average 1.140758382458725  and accuracy 61\n",
            "17201 steps out of 100 steps : average 1.0518390337527594  and accuracy 61\n",
            "17301 steps out of 100 steps : average 1.1937126714649764  and accuracy 59\n",
            "17401 steps out of 100 steps : average 1.0598019743978404  and accuracy 65\n",
            "17501 steps out of 100 steps : average 1.0558578763953002  and accuracy 63\n",
            "17601 steps out of 100 steps : average 1.1901899616566094  and accuracy 54\n",
            "17701 steps out of 100 steps : average 1.1788032862555675  and accuracy 57\n",
            "17801 steps out of 100 steps : average 0.9533218906103671  and accuracy 68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eng8RmPqs6tR",
        "colab_type": "code",
        "outputId": "1f0f2ca5-7804-4bef-dfb6-ca702591f3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "loss = 0\n",
        "num_correct = 0\n",
        "for im,label in zip(x_test,y_test):\n",
        "  _,l1,acc = forward(im,label)\n",
        "  loss += l1\n",
        "  num_correct += acc\n",
        "num_test = len(x_test)\n",
        "print(\"Test loss :\",loss/num_test)\n",
        "print(\"Test accuracy :\",num_correct/num_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-243dd9a5b1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-c9782dda287c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(img, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-067762a57ffe>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mconv_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_patch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mconv_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_patch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdl_dout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#dl_dout -> max-pool değeriyle gelecek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2087\u001b[0m def _sum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,\n\u001b[1;32m   2088\u001b[0m                     initial=None, where=None):\n\u001b[0;32m-> 2089\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}